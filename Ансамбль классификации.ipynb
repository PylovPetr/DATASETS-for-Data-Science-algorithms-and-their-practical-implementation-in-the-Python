{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи\n",
    "Загрузим данные, приведем их к числовым, заполним пропуски, нормализуем данные и оптимизируем память.\n",
    "\n",
    "Разделим выборку на обучающую/проверочную в соотношении 80/20.\n",
    "\n",
    "Сформируем параллельный ансамбль из логистической регрессии, SVM, случайного леса и LightGBM. Используем лучшие гиперпараметры, подобранные ранее. Итоговое решение рассчитаем на основании весов (вероятностей).\n",
    "\n",
    "Проведем предсказание и проверим качество через каппа-метрику.\n",
    "\n",
    "Данные:\n",
    "* https://video.ittensive.com/machine-learning/prudential/train.csv.gz\n",
    "\n",
    "Соревнование: https://www.kaggle.com/c/prudential-life-insurance-assessment/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59381 entries, 0 to 59380\n",
      "Columns: 128 entries, Id to Response\n",
      "dtypes: float64(18), int64(109), object(1)\n",
      "memory usage: 58.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://video.ittensive.com/machine-learning/prudential/train.csv.gz\")\n",
    "print (data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Product_Info_2_1\"] = data[\"Product_Info_2\"].str.slice(0, 1)\n",
    "data[\"Product_Info_2_2\"] = pd.to_numeric(data[\"Product_Info_2\"].str.slice(1, 2))\n",
    "data.drop(labels=[\"Product_Info_2\"], axis=1, inplace=True)\n",
    "for l in data[\"Product_Info_2_1\"].unique():\n",
    "    data[\"Product_Info_2_1\" + l] = data[\"Product_Info_2_1\"].isin([l]).astype(\"int8\")\n",
    "data.drop(labels=[\"Product_Info_2_1\"], axis=1, inplace=True)\n",
    "data.fillna(value=-1, inplace=True)\n",
    "data[\"Response\"] = data[\"Response\"] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Набор столбцов для расчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wt', 'Ht', 'Ins_Age', 'BMI', 'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', 'Insurance_History_4', 'Insurance_History_5', 'Insurance_History_7', 'Insurance_History_8', 'Insurance_History_9', 'Medical_Keyword_1', 'Medical_Keyword_2', 'Medical_Keyword_3', 'Medical_Keyword_4', 'Medical_Keyword_5', 'Medical_Keyword_6', 'Medical_Keyword_7', 'Medical_Keyword_8', 'Medical_Keyword_9', 'Medical_Keyword_10', 'Medical_Keyword_11', 'Medical_Keyword_12', 'Medical_Keyword_13', 'Medical_Keyword_14', 'Medical_Keyword_15', 'Medical_Keyword_16', 'Medical_Keyword_17', 'Medical_Keyword_18', 'Medical_Keyword_19', 'Medical_Keyword_20', 'Medical_Keyword_21', 'Medical_Keyword_22', 'Medical_Keyword_23', 'Medical_Keyword_24', 'Medical_Keyword_25', 'Medical_Keyword_26', 'Medical_Keyword_27', 'Medical_Keyword_28', 'Medical_Keyword_29', 'Medical_Keyword_30', 'Medical_Keyword_31', 'Medical_Keyword_32', 'Medical_Keyword_33', 'Medical_Keyword_34', 'Medical_Keyword_35', 'Medical_Keyword_36', 'Medical_Keyword_37', 'Medical_Keyword_38', 'Medical_Keyword_39', 'Medical_Keyword_40', 'Medical_Keyword_41', 'Medical_Keyword_42', 'Medical_Keyword_43', 'Medical_Keyword_44', 'Medical_Keyword_45', 'Medical_Keyword_46', 'Medical_Keyword_47', 'Medical_Keyword_48', 'Family_Hist_1', 'Family_Hist_2', 'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5', 'Medical_History_1', 'Medical_History_2', 'Medical_History_3', 'Medical_History_4', 'Medical_History_5', 'Medical_History_6', 'Medical_History_7', 'Medical_History_8', 'Medical_History_9', 'Medical_History_10', 'Medical_History_11', 'Medical_History_12', 'Medical_History_13', 'Medical_History_14', 'Medical_History_15', 'Medical_History_16', 'Medical_History_17', 'Medical_History_18', 'Medical_History_19', 'Medical_History_20', 'Medical_History_21', 'Medical_History_22', 'Medical_History_23', 'Medical_History_24', 'Medical_History_25', 'Medical_History_26', 'Medical_History_27', 'Medical_History_28', 'Medical_History_29', 'Medical_History_30', 'Medical_History_31', 'Medical_History_32', 'Medical_History_33', 'Medical_History_34', 'Medical_History_35', 'Medical_History_36', 'Medical_History_37', 'Medical_History_38', 'Medical_History_39', 'Medical_History_40', 'Medical_History_41', 'Product_Info_1', 'Product_Info_3', 'Product_Info_4', 'Product_Info_5', 'Product_Info_6', 'Product_Info_7', 'Product_Info_2_2', 'Product_Info_2_1D', 'Product_Info_2_1A', 'Product_Info_2_1E', 'Product_Info_2_1C', 'Product_Info_2_1B']\n"
     ]
    }
   ],
   "source": [
    "columns_groups = [\"Insurance_History\", \"InsurеdInfo\", \"Medical_Keyword\",\n",
    "                  \"Family_Hist\", \"Medical_History\", \"Product_Info\"]\n",
    "columns = [\"Wt\", \"Ht\", \"Ins_Age\", \"BMI\"]\n",
    "for cg in columns_groups:\n",
    "    columns.extend(data.columns[data.columns.str.startswith(cg)])\n",
    "print (columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "data_transformed = pd.DataFrame(scaler.fit_transform(pd.DataFrame(data,\n",
    "                                                     columns=columns)))\n",
    "columns_transformed = data_transformed.columns\n",
    "data_transformed[\"Response\"] = data[\"Response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизация памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage (df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if str(col_type)[:5] == \"float\":\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.finfo(\"f2\").min and c_max < np.finfo(\"f2\").max:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "            elif c_min > np.finfo(\"f4\").min and c_max < np.finfo(\"f4\").max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float64)\n",
    "        elif str(col_type)[:3] == \"int\":\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.iinfo(\"i1\").min and c_max < np.iinfo(\"i1\").max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif c_min > np.iinfo(\"i2\").min and c_max < np.iinfo(\"i2\").max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif c_min > np.iinfo(\"i4\").min and c_max < np.iinfo(\"i4\").max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "            elif c_min > np.iinfo(\"i8\").min and c_max < np.iinfo(\"i8\").max:\n",
    "                df[col] = df[col].astype(np.int64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Потребление памяти меньше на', round(start_mem - end_mem, 2), 'Мб (минус', round(100 * (start_mem - end_mem) / start_mem, 1), '%)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потребление памяти меньше на 40.49 Мб (минус 75.1 %)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59381 entries, 0 to 59380\n",
      "Columns: 119 entries, 0 to Response\n",
      "dtypes: float16(118), int8(1)\n",
      "memory usage: 13.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_transformed = reduce_mem_usage(data_transformed)\n",
    "print (data_transformed.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение данных\n",
    "Преобразуем выборки в отдельные наборы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6  \\\n",
      "16581 -0.748535 -0.710449  0.365479 -0.500488 -1.634766 -0.169434  0.862305   \n",
      "32658 -0.630859 -1.200195 -0.997070 -0.017761  0.611816 -0.169434  0.862305   \n",
      "13818 -0.748535 -0.710449  0.895020 -0.500488  0.611816 -0.169434 -1.159180   \n",
      "5607  -0.513672 -0.955078  1.727539 -0.016434  0.611816 -0.169434 -1.159180   \n",
      "54265  0.308838  1.249023  1.424805 -0.352295 -1.634766 -0.169434  0.862305   \n",
      "\n",
      "              7         8         9  ...       109       110       111  \\\n",
      "16581 -1.013672  0.864746 -0.928711  ... -0.083679  0.441650 -0.149292   \n",
      "32658 -1.013672  0.862305 -0.928711  ... -0.083679  0.441650 -0.149292   \n",
      "13818  1.100586 -1.156250  1.130859  ... -0.083679  0.441650 -0.149292   \n",
      "5607   1.100586 -1.156250  1.130859  ... -0.083679  0.441650 -0.149292   \n",
      "54265 -1.013672  0.874512 -0.928711  ... -0.083679 -2.263672 -0.149292   \n",
      "\n",
      "            112       113       114       115       116      117  Response  \n",
      "16581 -0.200073  0.750977 -0.623535 -0.215942 -0.128906 -0.14209         7  \n",
      "32658 -0.200073 -1.332031  1.604492 -0.215942 -0.128906 -0.14209         5  \n",
      "13818  1.666992 -1.332031  1.604492 -0.215942 -0.128906 -0.14209         4  \n",
      "5607   1.666992 -1.332031  1.604492 -0.215942 -0.128906 -0.14209         4  \n",
      "54265 -1.133789  0.750977 -0.623535 -0.215942 -0.128906 -0.14209         7  \n",
      "\n",
      "[5 rows x 119 columns]\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(data_transformed,\n",
    "                                         test_size=0.2)\n",
    "data_train = pd.DataFrame(data_train)\n",
    "data_test = pd.DataFrame(data_test)\n",
    "print (data_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение базовых моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(data_train, columns=columns_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nikolay\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\svm\\_base.py:231: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
       "    max_iter=10000, probability=True, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_svm = SVC(kernel='linear', probability=True, max_iter=10000)\n",
    "model_svm.fit(x, data_train[\"Response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logr = LogisticRegression(max_iter=1000)\n",
    "model_logr.fit(x, data_train[\"Response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Случайный лес"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=17, max_features=27,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=20, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=76,\n",
       "                       n_jobs=None, oob_score=False, random_state=17, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf = RandomForestClassifier(random_state=17, n_estimators=76,\n",
    "            max_depth=17, max_features=27, min_samples_leaf=20)\n",
    "model_rf.fit(x, data_train[\"Response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LightGBM, используем multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\nikolay\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\lightgbm\\engine.py:148: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.1, max_depth=18,\n",
       "              min_child_samples=18, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=100, n_jobs=-1, num_boost_round=1000, num_class=8,\n",
       "              num_leaves=75, objective='multiclass', random_state=17,\n",
       "              reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "              subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lgb = lgb.LGBMRegressor(random_state=17, max_depth=18,\n",
    "            min_child_samples=18, num_leaves=75, n_estimators=1000,\n",
    "            objective=\"multiclass\", num_class=8)\n",
    "model_lgb.fit(x, data_train[\"Response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Расчет предказаний\n",
    "Кроме непосредственно значений дополнительно посчитаем вероятности совпадения с тем или иным классом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.DataFrame(data_test, columns=columns_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_svm_proba = pd.DataFrame(model_svm.predict_proba(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_logr_proba = pd.DataFrame(model_logr.predict_proba(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_rf_proba = pd.DataFrame(model_rf.predict_proba(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_lgb = pd.DataFrame(model_lgb.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Несколько вариантов ансамблей с голосованием (выбор класса выполняется для каждого кортежа по отдельности):\n",
    "* \"Мягкое\" голосование (в том числе, с определенными весами): суммируются вероятности каждого класса среди всех оценок, выбирается наибольшее.\n",
    "* \"Жесткое\" (мажоритарное) голосование: выбирается самый популярный класс среди моделей (число моделей должно быть нечетным).\n",
    "* Отсечение: из вероятностей моделей выбирается только наиболее значимые, например, больше 0.3.\n",
    "* Экспертное голосование: вес оценки эксперта зависит от кортежа данных и самого класса (например, если определенная модель предсказывает определенный класс точнее других).\n",
    "\n",
    "Здесь используем \"мягкое\" голосование, для этого необходимо рассчитать вероятности всех класса для каждого кортежа данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vote_class (x):\n",
    "    a = np.argmax(x.values)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test_proba = data_test_svm_proba.copy()\n",
    "for i in range(0, 8):\n",
    "    data_test_proba[i] = 5*data_test_proba[i]\n",
    "    data_test_proba[i] = data_test_proba[i] + 5*data_test_logr_proba[i]\n",
    "    data_test_proba[i] = data_test_proba[i] + data_test_rf_proba[i]\n",
    "    data_test_proba[i] = data_test_proba[i] + 12*data_test_lgb[i]\n",
    "data_test_proba[\"target\"] = data_test_proba.apply(vote_class, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка ансамбля\n",
    "Рассчитаем оценку взвешенного предсказания 4 моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластеризация дает 0.192, kNN(100) - 0.382, лог. регрессия - 0.512/0.496, SVM - 0.95, реш. дерево - 0.3, случайный лес - 0.487, XGBoost - 0.536, градиентный бустинг - 0.56, LightGBM - 0.569, CatBoost - 0.542"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ансамбль классификации: 0.56\n"
     ]
    }
   ],
   "source": [
    "print (\"Ансамбль классификации:\",\n",
    "      round(cohen_kappa_score(data_test_proba[\"target\"],\n",
    "                data_test[\"Response\"], weights=\"quadratic\"), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матрица неточностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ансамбль классификации\n",
      " [[ 300  151   15   27   53  123   31   18]\n",
      " [ 172  329   20    8   99   87   25   21]\n",
      " [  22   23   74   13    0    1    0    0]\n",
      " [  32   22   56  182    0    2    1    4]\n",
      " [  88  142   17    0  568   85    8    5]\n",
      " [ 259  266   19   21  227 1255  324  122]\n",
      " [ 103   96    1    5   46  262  606  123]\n",
      " [ 250  232    3   34  109  491  596 3603]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Ансамбль классификации\\n\",\n",
    "    confusion_matrix(data_test_proba[\"target\"], data_test[\"Response\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Само-проверка\n",
    "Проверим, насколько ансамбль хорошо предсказывает обучающие данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy = data_train.copy()\n",
    "x_copy = pd.DataFrame(data_copy, columns=columns_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy_svm = pd.DataFrame(model_svm.predict_proba(x_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy_logr = pd.DataFrame(model_logr.predict_proba(x_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy_rf = pd.DataFrame(model_rf.predict_proba(x_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_copy_lgb = pd.DataFrame(model_lgb.predict(x_copy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, 8):\n",
    "    data_copy_svm[i] = 5*data_copy_svm[i]\n",
    "    data_copy_svm[i] = data_copy_svm[i] + 5*data_copy_logr[i]\n",
    "    data_copy_svm[i] = data_copy_svm[i] + data_copy_rf[i]\n",
    "    data_copy_svm[i] = data_copy_svm[i] + 12*data_copy_lgb[i]\n",
    "target = data_copy_svm.apply(vote_class, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Результат: 0.964\n"
     ]
    }
   ],
   "source": [
    "print (\"Результат:\",\n",
    "      round(cohen_kappa_score(target,\n",
    "                data_copy[\"Response\"], weights=\"quadratic\"), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4741     0     0     0     0     0     0     0]\n",
      " [    1  5041     0     0     0     0     0     0]\n",
      " [    0     0   808     0     0     0     0     0]\n",
      " [    0     0     0  1138     0     0     0     0]\n",
      " [    3     6     0     0  4289     0     0     0]\n",
      " [   38    46     0     0     8  8476     6     2]\n",
      " [   13    13     0     0     1    15  5889     1]\n",
      " [  185   185     0     0    32   436   541 15590]]\n"
     ]
    }
   ],
   "source": [
    "print (confusion_matrix(target, data_copy[\"Response\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
