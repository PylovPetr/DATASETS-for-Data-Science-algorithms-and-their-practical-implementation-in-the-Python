{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи\n",
    "Загрузим подготовленные данные из HDF5. Разделим данные на обучающие и проверочные и построим двухслойный перцептрон для типа облака Fish.\n",
    "\n",
    "Проведем оценку качества предсказания по коэффициенту сходства.\n",
    "\n",
    "Данные:\n",
    "* https://video.ittensive.com/machine-learning/clouds/clouds.data.h5 (959 Мб)\n",
    "\n",
    "Соревнование: https://www.kaggle.com/c/understanding_cloud_organization/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используемые функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_x = 525\n",
    "image_y = 350\n",
    "def mask_rate (a, x, y):\n",
    "    b = a//1400 + 0.0\n",
    "    return np.round(x*(b*x//2100) + y*(a%1400)//1400).astype(\"uint32\")\n",
    "\n",
    "def calc_mask (px, x=image_x, y=image_y):\n",
    "    p = np.array([int(n) for n in px.split(' ')]).reshape(-1,2)\n",
    "    mask = np.zeros(x*y, dtype='uint8')\n",
    "    for i, l in p:\n",
    "        mask[mask_rate(i, x, y) - 1:mask_rate(l+i, x, y)] = 1\n",
    "    return mask.reshape(y,x).transpose()\n",
    "\n",
    "def calc_dice (x):\n",
    "    dice = 0\n",
    "    px = x[\"EncodedPixels\"] \n",
    "    if px != px and x[\"target\"] == 0:\n",
    "        dice = 1\n",
    "    elif px == px and x[\"target\"] == 1:\n",
    "        mask = calc_mask(px).flatten()\n",
    "        target = np.ones(image_x*image_y, dtype='uint8')\n",
    "        dice = 2*np.sum(target[mask==1])/(np.sum(target)+np.sum(mask))\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0   1    2    3    4    5    6    7    8    9  ...  183745  183746  \\\n",
      "0   0   0    0    0    0    0    0    0    0    0  ...     102     113   \n",
      "1  71  42   31   38   48   68   70   46   24   21  ...      38      57   \n",
      "2  97  98  100  102  105  107  109  110  111  112  ...       0       0   \n",
      "3  87  86   89   93   93   88   86   86   81   81  ...     165     164   \n",
      "4  18  19   21   21   20   19   17   16   14   15  ...     125     137   \n",
      "\n",
      "   183747  183748  183749        Image  \\\n",
      "0     102      96     116  0011165.jpg   \n",
      "1      82     110     133  002be4f.jpg   \n",
      "2       0       0       0  0031ae9.jpg   \n",
      "3     108      70      72  0035239.jpg   \n",
      "4      92      59      48  003994e.jpg   \n",
      "\n",
      "                                                Fish  \\\n",
      "0  264918 937 266318 937 267718 937 269118 937 27...   \n",
      "1  233813 878 235213 878 236613 878 238010 881 23...   \n",
      "2  3510 690 4910 690 6310 690 7710 690 9110 690 1...   \n",
      "3                                                NaN   \n",
      "4  2367966 18 2367985 2 2367993 8 2368002 62 2369...   \n",
      "\n",
      "                                              Flower  \\\n",
      "0  1355565 1002 1356965 1002 1358365 1002 1359765...   \n",
      "1  1339279 519 1340679 519 1342079 519 1343479 51...   \n",
      "2  2047 703 3447 703 4847 703 6247 703 7647 703 9...   \n",
      "3  100812 462 102212 462 103612 462 105012 462 10...   \n",
      "4                                                NaN   \n",
      "\n",
      "                                              Gravel  \\\n",
      "0                                                NaN   \n",
      "1                                                NaN   \n",
      "2                                                NaN   \n",
      "3  65400 380 66800 380 68200 380 69600 380 71000 ...   \n",
      "4  353317 416 354717 416 356117 416 357517 416 35...   \n",
      "\n",
      "                                               Sugar  \n",
      "0                                                NaN  \n",
      "1  67495 350 68895 350 70295 350 71695 350 73095 ...  \n",
      "2  658170 388 659570 388 660970 388 662370 388 66...  \n",
      "3                                                NaN  \n",
      "4  28011 489 29411 489 30811 489 32211 489 33611 ...  \n",
      "\n",
      "[5 rows x 183755 columns]\n"
     ]
    }
   ],
   "source": [
    "clouds = pd.read_hdf('clouds.data.h5')\n",
    "print (clouds.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставим только данные по Fish, на них обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clouds.drop(labels=[\"Image\", \"Flower\", \"Gravel\", \"Sugar\"],\n",
    "    axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение данных\n",
    "Разделим всю выборку на 2 части случайным образом: 80% - для обучения модели, 20% - для проверки точности модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0    1    2    3    4    5    6    7    8    9  ...  183741  183742  \\\n",
      "1841   42   32   32   25    4    0    2    2    0    0  ...      19      18   \n",
      "5196  149  149  148  147  147  146  146  145  146  145  ...      90      92   \n",
      "2006  104  134  114   56   30   34   39   43   50   77  ...      46      49   \n",
      "1948   39   36   32   30   31   32   33   33   32   32  ...     220     227   \n",
      "4561  161  159  145  163  180  165  153  143  142  142  ...     161     214   \n",
      "\n",
      "      183743  183744  183745  183746  183747  183748  183749  \\\n",
      "1841      17      17      17      17      17      17      18   \n",
      "5196      95      92      98     118     119     102      97   \n",
      "2006      43      43      44      45      45      46      47   \n",
      "1948     225     227     220     218     211     212     226   \n",
      "4561     236     241     228     235     219     197     202   \n",
      "\n",
      "                                                   Fish  \n",
      "1841  1768642 682 1770042 682 1771442 682 1772842 68...  \n",
      "5196                                                NaN  \n",
      "2006  15839 323 17034 597 18434 597 19834 597 21234 ...  \n",
      "1948                                                NaN  \n",
      "4561  1345165 235 1346565 235 1347965 235 1349365 23...  \n",
      "\n",
      "[5 rows x 183751 columns]\n"
     ]
    }
   ],
   "source": [
    "clouds_train, clouds_test = train_test_split(clouds, test_size=0.2)\n",
    "clouds_train = pd.DataFrame(clouds_train)\n",
    "clouds_test = pd.DataFrame(clouds_test)\n",
    "del clouds\n",
    "print (clouds_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Двухслойный перцептрон\n",
    "![](https://www.researchgate.net/profile/Yan-Fu_Li/publication/281534869/figure/fig4/AS:668235573755913@1536331184829/Architecture-of-a-MLP-NN-model.png)\n",
    "Последовательно рассчитываем коэффициенты для пакетов по 100 изображений, иначе может не поместиться в оперативную память.\n",
    "\n",
    "Используем warm_start=True, чтобы переиспользовать предыдущие параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = clouds_train[\"Fish\"].notnull().astype(\"int8\")\n",
    "x = pd.DataFrame(clouds_train).drop(labels=[\"Fish\"], axis=1)\n",
    "model = MLPClassifier(hidden_layer_sizes=(31,),\n",
    "                     max_iter=20, activation=\"logistic\",\n",
    "                     verbose=10, random_state=1, learning_rate_init=.02,\n",
    "                     warm_start=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.72517492\n",
      "Iteration 2, loss = 0.69139934\n",
      "Iteration 3, loss = 0.69218115\n",
      "Iteration 4, loss = 0.68995657\n",
      "Iteration 5, loss = 0.69197143\n",
      "Iteration 6, loss = 0.69507116\n",
      "Iteration 7, loss = 0.69910045\n",
      "Iteration 8, loss = 0.69878797\n",
      "Iteration 9, loss = 0.69840872\n",
      "Iteration 10, loss = 0.70072479\n",
      "Iteration 11, loss = 0.70232555\n",
      "Iteration 12, loss = 0.70359634\n",
      "Iteration 13, loss = 0.70379597\n",
      "Iteration 14, loss = 0.70544680\n",
      "Iteration 15, loss = 0.70782095\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 16, loss = 0.70839137\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 17, loss = 0.70856360\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 18, loss = 0.70944267\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 19, loss = 0.70964819\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 20, loss = 0.70895729\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 21, loss = 0.71133075\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 22, loss = 0.71188986\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 23, loss = 0.71224260\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 24, loss = 0.71448954\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 25, loss = 0.71446970\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 26, loss = 0.71322945\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 27, loss = 0.71348998\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 28, loss = 0.71048460\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 29, loss = 0.71189176\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 30, loss = 0.71161251\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 31, loss = 0.71410100\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 32, loss = 0.71414996\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 33, loss = 0.71141037\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 34, loss = 0.71302719\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 35, loss = 0.71665775\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 36, loss = 0.71366820\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 37, loss = 0.71583937\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 38, loss = 0.71380622\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 39, loss = 0.71372494\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 40, loss = 0.71127399\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 41, loss = 0.70911602\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 42, loss = 0.70797922\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 43, loss = 0.71149940\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "Iteration 44, loss = 0.70895588\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(clouds_train)//100):\n",
    "    model.partial_fit(x[i:i+100], y[i:i+100], classes=[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del x\n",
    "del y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          EncodedPixels  target\n",
      "2545                                                NaN       0\n",
      "588   1663220 690 1664620 690 1666020 690 1667420 69...       0\n",
      "1852                                                NaN       0\n",
      "5237  1332363 411 1333763 411 1335163 411 1336563 41...       0\n",
      "927   9477 314 10877 314 12277 314 13677 314 15077 3...       0\n",
      "5096  6604 394 8004 394 9404 394 10804 394 12204 394...       0\n",
      "4846  2073 400 3473 393 3870 3 4873 390 5264 9 6273 ...       0\n",
      "3162  280828 366 282228 366 283628 366 285028 366 28...       1\n",
      "1840  373209 10 373223 4 373230 3 373234 2 373237 1 ...       0\n",
      "3340  579631 833 581031 833 582431 833 583831 833 58...       0\n"
     ]
    }
   ],
   "source": [
    "result = pd.DataFrame({\"EncodedPixels\": clouds_test[\"Fish\"]})\n",
    "result[\"target\"] = model.predict(clouds_test.drop(labels=[\"Fish\"],\n",
    "                                                 axis=1))\n",
    "print (result.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка по Дайсу\n",
    "Пока будем считать, что при определении типа облака на изображении, оно целиком размещено на фотографии: т.е. область облака - это все изображение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нет облаков - 0.5, опорные векторы - 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP, Fish: 0.498\n"
     ]
    }
   ],
   "source": [
    "dice = result.apply(calc_dice, axis=1, result_type=\"expand\")\n",
    "print (\"MLP, Fish:\", round(dice.mean(), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
