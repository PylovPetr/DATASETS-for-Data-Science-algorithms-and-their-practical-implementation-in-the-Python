{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи\n",
    "Разработаем оптимальную архитектуру нейронной сети, исходя из исходной задачи классификации.\n",
    "\n",
    "Разделим данные на обучающие и проверочные в соотношении 80/20.\n",
    "\n",
    "Используем Keras для построения нейросети с линейным, сверточными слоями и слоями подвыборки.\n",
    "\n",
    "Проведем оценку качества предсказания по коэффициенту сходства.\n",
    "\n",
    "Данные:\n",
    "* https://video.ittensive.com/machine-learning/clouds/train.csv.gz (54 Мб)\n",
    "* https://video.ittensive.com/machine-learning/clouds/train_images_small.tar.gz (212 Мб)\n",
    "\n",
    "Соревнование: https://www.kaggle.com/c/understanding_cloud_organization/\n",
    "\n",
    "![](inception-resnet-v2.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage import io\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Activation, Flatten\n",
    "from keras.layers import Concatenate, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, ZeroPadding2D\n",
    "from keras.regularizers import l2\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import optimizers\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Используемые функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filesDir = \"train_images_small\"\n",
    "batch_size = 20\n",
    "image_x = 525\n",
    "image_y = 350\n",
    "image_ch = 3\n",
    "def mask_rate (a, x, y):\n",
    "    b = a//1400 + 0.0\n",
    "    return np.round(x*(b*x//2100) + y*(a%1400)//1400).astype(\"uint32\")\n",
    "\n",
    "def calc_mask (px, x=image_x, y=image_y):\n",
    "    p = np.array([int(n) for n in px.split(' ')]).reshape(-1,2)\n",
    "    mask = np.zeros(x*y, dtype='uint8')\n",
    "    for i, l in p:\n",
    "        mask[mask_rate(i, x, y) - 1:mask_rate(l+i, x, y)] = 1\n",
    "    return mask.reshape(y,x).transpose()\n",
    "\n",
    "def calc_dice (x):\n",
    "    dice = 0\n",
    "    px = x[\"EncodedPixels\"] \n",
    "    if px != px and x[\"target\"] == 0:\n",
    "        dice = 1\n",
    "    elif px == px and x[\"target\"] == 1:\n",
    "        mask = calc_mask(px).flatten()\n",
    "        target = np.ones(image_x*image_y, dtype='uint8')\n",
    "        dice += 2*np.sum(target[mask==1])/(np.sum(target)+np.sum(mask))\n",
    "    return dice\n",
    "\n",
    "def load_y (df):\n",
    "    return np.array(df[\"EncodedPixels\"].notnull().astype(\"int8\")).reshape(len(df), 1)\n",
    "\n",
    "def load_x (df):\n",
    "    x = [[]]*len(df)\n",
    "    for j, file in enumerate(df[\"Image\"]):\n",
    "        img = image.load_img(os.path.join(filesDir, file),\n",
    "                     target_size=(image_y, image_x))\n",
    "        img = image.img_to_array(img)\n",
    "        x[j] = np.expand_dims(img, axis=0)\n",
    "    return np.array(x).reshape(len(df), image_y, image_x, image_ch)\n",
    "\n",
    "def load_data (df, batch_size):\n",
    "    while True:\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "        while batch_start < len(df):\n",
    "            limit = min(batch_end, len(df))\n",
    "            yield (load_x(df[batch_start:limit]),\n",
    "                   load_y(df[batch_start:limit]))\n",
    "            batch_start += batch_size\n",
    "            batch_end += batch_size\n",
    "\n",
    "def draw_prediction (prediction):\n",
    "    fig = plt.figure(figsize=(16, 8))\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.hist(prediction[0])\n",
    "    ax.set_title(\"Fish\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://video.ittensive.com/machine-learning/clouds/train.csv.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        EncodedPixels        Image Label\n",
      "0   264918 937 266318 937 267718 937 269118 937 27...  0011165.jpg  Fish\n",
      "4   233813 878 235213 878 236613 878 238010 881 23...  002be4f.jpg  Fish\n",
      "8   3510 690 4910 690 6310 690 7710 690 9110 690 1...  0031ae9.jpg  Fish\n",
      "12                                                NaN  0035239.jpg  Fish\n",
      "16  2367966 18 2367985 2 2367993 8 2368002 62 2369...  003994e.jpg  Fish\n"
     ]
    }
   ],
   "source": [
    "data[\"Image\"] = data[\"Image_Label\"].str.split(\"_\").str[0]\n",
    "data[\"Label\"] = data[\"Image_Label\"].str.split(\"_\").str[1]\n",
    "data.drop(labels=[\"Image_Label\"], axis=1, inplace=True)\n",
    "data_fish = data[data[\"Label\"] == \"Fish\"]\n",
    "print (data_fish.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение данных\n",
    "Разделим всю выборку на 2 части случайным образом: 80% - для обучения модели, 20% - для проверки точности модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           EncodedPixels        Image Label\n",
      "13216                                                NaN  965b308.jpg  Fish\n",
      "7092   1288267 1121 1289667 1121 1291067 1121 1292467...  5122a3d.jpg  Fish\n",
      "10220                                                NaN  74808ec.jpg  Fish\n",
      "14052  57604 446 59004 446 60404 446 61804 446 63204 ...  a0e6825.jpg  Fish\n",
      "3160                                                 NaN  2385676.jpg  Fish\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(data_fish, test_size=0.2)\n",
    "train = pd.DataFrame(train)\n",
    "test = pd.DataFrame(test)\n",
    "del data\n",
    "print (train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Архитектура нейросети\n",
    "Для выделения характерных особенностей на исходном изображении достаточно ввести несколько сверточных блоков, как предложено в GoogLeNet/Inception: 1x1, 3x3, 2-3x3 и объединить их через MaxPool.\n",
    "\n",
    "Количество таких блоков будет зависеть от размера области на изображении, которую классифицируем. В случае изображения 525x350 \"пятно\" облака занимает 2/3 по каждому измерению, до 350x233.\n",
    "\n",
    "Перед запуском сверточных блоков добавим инициализацию: свертку 3x3 и подвыборку, чтобы уменьшить размерность изображения, это сократит \"пятно\" в 4 раза, до 58 пикселей. После этого каждый сверточно-выборочный блок уменьшает размер \"пятна\" в 2 раза => необходимо 3-4 таких блока для успешной классификации (минимальный размер блока после финальной подвыборки - 4, lg(58/4) = 3,8).\n",
    "\n",
    "Padding-слои нужны для выравнивания размеров входов для объединения на выходе нескольких потоков обработки изображения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input(shape=(image_y, image_x, image_ch))\n",
    "start_3x3 = Conv2D(32, (3,3), padding=\"valid\",\n",
    "                   strides=(2,2),\n",
    "                   kernel_regularizer=l2(0.0002),\n",
    "                   kernel_initializer='glorot_uniform')(inp)\n",
    "start_3x3_act = Activation(\"relu\")(start_3x3)\n",
    "start_3x3_pool = MaxPooling2D(pool_size=(2,2),\n",
    "                    padding=\"same\")(start_3x3_act)\n",
    "input_ = start_3x3_pool\n",
    "for i in range(3):\n",
    "    inc_1x1 = Conv2D(32, (1,1), padding=\"valid\",\n",
    "                   kernel_regularizer=l2(0.0002),\n",
    "                   kernel_initializer='glorot_uniform')(input_)\n",
    "    inc_1x1_act = Activation(\"relu\")(inc_1x1)\n",
    "    inc_3x3 = Conv2D(16, (1,1), padding=\"valid\",\n",
    "                   kernel_regularizer=l2(0.0002),\n",
    "                   kernel_initializer='glorot_uniform')(input_)\n",
    "    inc_3x3_act = Activation(\"relu\")(inc_3x3)\n",
    "    inc_3x3_2 = Conv2D(32, (3,3), padding=\"valid\",\n",
    "                   kernel_regularizer=l2(0.0002),\n",
    "                   kernel_initializer='glorot_uniform')(inc_3x3_act)\n",
    "    inc_3x3_2_pad = ZeroPadding2D(padding=(1,1))(inc_3x3_2)\n",
    "    inc_3x3_2_act = Activation(\"relu\")(inc_3x3_2_pad)\n",
    "    inc_5x5 = Conv2D(16, (1,1), padding=\"valid\",\n",
    "                   kernel_regularizer=l2(0.0002),\n",
    "                   kernel_initializer='glorot_uniform')(input_)\n",
    "    inc_5x5_act = Activation(\"relu\")(inc_5x5)\n",
    "    inc_5x5_2 = Conv2D(32, (5,5), padding=\"valid\",\n",
    "                   kernel_regularizer=l2(0.0002),\n",
    "                   kernel_initializer='glorot_uniform')(inc_5x5_act)\n",
    "    inc_5x5_2_pad = ZeroPadding2D(padding=(2,2))(inc_5x5_2)\n",
    "    inc_5x5_2_act = Activation(\"relu\")(inc_5x5_2_pad)\n",
    "    inc_pool = MaxPooling2D(pool_size=(3,3), strides=(1,1),\n",
    "                    padding=\"same\")(input_)\n",
    "    inc_pool_1x1 = Conv2D(32, (1,1), padding=\"same\",\n",
    "                   kernel_regularizer=l2(0.0002),\n",
    "                   kernel_initializer='glorot_uniform')(inc_pool)\n",
    "    inc_pool_1x1_act = Activation(\"relu\")(inc_pool_1x1)\n",
    "    inc_conc = Concatenate(axis=1)([inc_1x1_act, inc_3x3_2_act,\n",
    "                    inc_5x5_2_act, inc_pool_1x1_act])\n",
    "    inc_output = MaxPooling2D(pool_size=(2,2),\n",
    "                    padding=\"same\")(inc_conc)\n",
    "    input_ = inc_output\n",
    "flat = Flatten()(input_)\n",
    "flat_bn = BatchNormalization()(flat)\n",
    "drop = Dropout(0.5)(flat_bn)\n",
    "drop_act = Activation(\"softmax\")(drop)\n",
    "final = Dense(1)(drop_act)\n",
    "model = Model(inputs=inp, outputs=final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 350, 525, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 174, 262, 32) 896         input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 174, 262, 32) 0           conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_75 (MaxPooling2D) (None, 87, 131, 32)  0           activation_204[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 87, 131, 16)  528         max_pooling2d_75[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 87, 131, 16)  528         max_pooling2d_75[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_206 (Activation)     (None, 87, 131, 16)  0           conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 87, 131, 16)  0           conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 85, 129, 32)  4640        activation_206[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 83, 127, 32)  12832       activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_76 (MaxPooling2D) (None, 87, 131, 32)  0           max_pooling2d_75[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 87, 131, 32)  1056        max_pooling2d_75[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_61 (ZeroPadding2 (None, 87, 131, 32)  0           conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_62 (ZeroPadding2 (None, 87, 131, 32)  0           conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 87, 131, 32)  1056        max_pooling2d_76[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 87, 131, 32)  0           conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 87, 131, 32)  0           zero_padding2d_61[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 87, 131, 32)  0           zero_padding2d_62[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 87, 131, 32)  0           conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_31 (Concatenate)    (None, 348, 131, 32) 0           activation_205[0][0]             \n",
      "                                                                 activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_77 (MaxPooling2D) (None, 174, 66, 32)  0           concatenate_31[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 174, 66, 16)  528         max_pooling2d_77[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 174, 66, 16)  528         max_pooling2d_77[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 174, 66, 16)  0           conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 174, 66, 16)  0           conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 172, 64, 32)  4640        activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 170, 62, 32)  12832       activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_78 (MaxPooling2D) (None, 174, 66, 32)  0           max_pooling2d_77[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 174, 66, 32)  1056        max_pooling2d_77[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_63 (ZeroPadding2 (None, 174, 66, 32)  0           conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_64 (ZeroPadding2 (None, 174, 66, 32)  0           conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 174, 66, 32)  1056        max_pooling2d_78[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 174, 66, 32)  0           conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 174, 66, 32)  0           zero_padding2d_63[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 174, 66, 32)  0           zero_padding2d_64[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 174, 66, 32)  0           conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_32 (Concatenate)    (None, 696, 66, 32)  0           activation_211[0][0]             \n",
      "                                                                 activation_213[0][0]             \n",
      "                                                                 activation_215[0][0]             \n",
      "                                                                 activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_79 (MaxPooling2D) (None, 348, 33, 32)  0           concatenate_32[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 348, 33, 16)  528         max_pooling2d_79[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 348, 33, 16)  528         max_pooling2d_79[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 348, 33, 16)  0           conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 348, 33, 16)  0           conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 346, 31, 32)  4640        activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 344, 29, 32)  12832       activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_80 (MaxPooling2D) (None, 348, 33, 32)  0           max_pooling2d_79[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 348, 33, 32)  1056        max_pooling2d_79[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_65 (ZeroPadding2 (None, 348, 33, 32)  0           conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_66 (ZeroPadding2 (None, 348, 33, 32)  0           conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 348, 33, 32)  1056        max_pooling2d_80[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 348, 33, 32)  0           conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 348, 33, 32)  0           zero_padding2d_65[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 348, 33, 32)  0           zero_padding2d_66[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 348, 33, 32)  0           conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_33 (Concatenate)    (None, 1392, 33, 32) 0           activation_217[0][0]             \n",
      "                                                                 activation_219[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_81 (MaxPooling2D) (None, 696, 17, 32)  0           concatenate_33[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 378624)       0           max_pooling2d_81[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 378624)       1514496     flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 378624)       0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 378624)       0           dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            378625      activation_223[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 1,955,937\n",
      "Trainable params: 1,198,689\n",
      "Non-trainable params: 757,248\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=optimizers.Nadam(lr=0.001),\n",
    "             loss=\"mean_absolute_error\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка модели\n",
    "Будем проверять эффективность модели на выборке 100 элементов и 10 эпохах обучения. Эффективная модель будет разделять предсказываемые классы облаков (распределение предсказания будет бимодальным)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим раннюю остановку обучения, если качество предсказания не улучшается в течение 5 эпох (patience)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "221/221 [==============================] - 15110s 68s/step - loss: 0.5419\n",
      "Epoch 2/100\n",
      "221/221 [==============================] - 1797s 8s/step - loss: 0.5074\n",
      "Epoch 3/100\n",
      "221/221 [==============================] - 1707s 8s/step - loss: 0.5038\n",
      "Epoch 4/100\n",
      "221/221 [==============================] - 1559s 7s/step - loss: 0.5031\n",
      "Epoch 5/100\n",
      "221/221 [==============================] - 1542s 7s/step - loss: 0.4897\n",
      "Epoch 6/100\n",
      "221/221 [==============================] - 1577s 7s/step - loss: 0.4815\n",
      "Epoch 7/100\n",
      "221/221 [==============================] - 1546s 7s/step - loss: 0.4782\n",
      "Epoch 8/100\n",
      "221/221 [==============================] - 1543s 7s/step - loss: 0.4694\n",
      "Epoch 9/100\n",
      "221/221 [==============================] - 1543s 7s/step - loss: 0.4667\n",
      "Epoch 10/100\n",
      "221/221 [==============================] - 1544s 7s/step - loss: 0.4591\n",
      "Epoch 11/100\n",
      "221/221 [==============================] - 1541s 7s/step - loss: 0.4469\n",
      "Epoch 12/100\n",
      "221/221 [==============================] - 1580s 7s/step - loss: 0.4470\n",
      "Epoch 13/100\n",
      "221/221 [==============================] - 1550s 7s/step - loss: 0.4410\n",
      "Epoch 14/100\n",
      "221/221 [==============================] - 1542s 7s/step - loss: 0.4374\n",
      "Epoch 15/100\n",
      "221/221 [==============================] - 1544s 7s/step - loss: 0.4403\n",
      "Epoch 16/100\n",
      "221/221 [==============================] - 1551s 7s/step - loss: 0.4600\n",
      "Epoch 17/100\n",
      "221/221 [==============================] - 1549s 7s/step - loss: 0.4547\n",
      "Epoch 18/100\n",
      "221/221 [==============================] - 1547s 7s/step - loss: 0.4505\n",
      "Epoch 19/100\n",
      "221/221 [==============================] - 1549s 7s/step - loss: 0.4479\n",
      "Epoch 00019: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x6b312888>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(load_data(train, batch_size),\n",
    "            epochs=100, steps_per_epoch=len(train)//batch_size,\n",
    "            verbose=True,\n",
    "            callbacks=[EarlyStopping(monitor=\"loss\",\n",
    "                min_delta=0.0001, patience=5, verbose=1, mode=\"auto\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1110/1110 [==============================] - 165s 149ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = model.predict_generator(load_data(test, 1),\n",
    "                        steps=len(test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prediction = np.transpose(prediction)\n",
    "draw_prediction(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"target\"] = (prediction[0] >= 0.5).astype(\"i1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11996                                                  NaN\n",
      "4716     1043235 786 1044635 786 1046035 786 1047435 78...\n",
      "13692    304082 904 305482 904 306882 904 308282 904 30...\n",
      "4808     830320 891 831720 891 833120 891 834520 891 83...\n",
      "1816                                                   NaN\n",
      "1964     586621 1173 588021 1173 589421 1173 590821 117...\n",
      "17236                                                  NaN\n",
      "16488    681915 838 683315 838 684715 838 686115 838 68...\n",
      "17668                                                  NaN\n",
      "11164    705617 8 707017 8 708402 7 708417 8 709802 5 7...\n",
      "9228     339667 482 341067 482 342467 482 343867 482 34...\n",
      "Name: EncodedPixels, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print (test[test[\"target\"]>0][\"EncodedPixels\"].head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка по Дайсу\n",
    "Пока будем считать, что при определении типа облака на изображении, оно целиком размещено на фотографии: т.е. область облака - это все изображение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нет облаков - 0.5, MLP - 0.3, CONV/VGG - 0.48, AlexNet - 0.2, Inception - 0.5, ResNet - 0.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras, (CONV3-32x2,POOL2,CONV1/CONV3/CONV5-x3,POOL2) 0.486\n"
     ]
    }
   ],
   "source": [
    "dice = test.apply(calc_dice, axis=1, result_type=\"expand\")\n",
    "print (\"Keras, (CONV3-32x2,POOL2,CONV1/CONV3/CONV5-x3,POOL2):\",\n",
    "      round(dice.mean(), 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
