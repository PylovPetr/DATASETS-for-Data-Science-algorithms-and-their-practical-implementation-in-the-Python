{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи\n",
    "Загрузим данные, приведем их к числовым, заполним пропуски, нормализуем данные и оптимизируем память.\n",
    "\n",
    "Разделим выборку на обучающую/проверочную в соотношении 80/20.\n",
    "\n",
    "Построим 4 модели логистической регрессии: для 8, 6 и остальных классов, для 2, 5 и остальных, для 1, 7 и остальных, и для 4 и 3 - по убыванию частоты значения. Будем использовать перекрестную проверку при принятии решения об оптимальном наборе столбцов.\n",
    "\n",
    "Проведем предсказание и проверим качество через каппа-метрику.\n",
    "\n",
    "Данные:\n",
    "* https://video.ittensive.com/machine-learning/prudential/train.csv.gz\n",
    "\n",
    "Соревнование: https://www.kaggle.com/c/prudential-life-insurance-assessment/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix, make_scorer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59381 entries, 0 to 59380\n",
      "Columns: 128 entries, Id to Response\n",
      "dtypes: float64(18), int64(109), object(1)\n",
      "memory usage: 58.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://video.ittensive.com/machine-learning/prudential/train.csv.gz\")\n",
    "print (data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Product_Info_2_1\"] = data[\"Product_Info_2\"].str.slice(0, 1)\n",
    "data[\"Product_Info_2_2\"] = pd.to_numeric(data[\"Product_Info_2\"].str.slice(1, 2))\n",
    "data.drop(labels=[\"Product_Info_2\"], axis=1, inplace=True)\n",
    "for l in data[\"Product_Info_2_1\"].unique():\n",
    "    data[\"Product_Info_2_1\" + l] = data[\"Product_Info_2_1\"].isin([l]).astype(\"int8\")\n",
    "data.drop(labels=[\"Product_Info_2_1\"], axis=1, inplace=True)\n",
    "data.fillna(value=-1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизация памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage (df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if str(col_type)[:5] == \"float\":\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.finfo(\"f2\").min and c_max < np.finfo(\"f2\").max:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "            elif c_min > np.finfo(\"f4\").min and c_max < np.finfo(\"f4\").max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float64)\n",
    "        elif str(col_type)[:3] == \"int\":\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.iinfo(\"i1\").min and c_max < np.iinfo(\"i1\").max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif c_min > np.iinfo(\"i2\").min and c_max < np.iinfo(\"i2\").max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif c_min > np.iinfo(\"i4\").min and c_max < np.iinfo(\"i4\").max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "            elif c_min > np.iinfo(\"i8\").min and c_max < np.iinfo(\"i8\").max:\n",
    "                df[col] = df[col].astype(np.int64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Потребление памяти меньше на', round(start_mem - end_mem, 2), 'Мб (минус', round(100 * (start_mem - end_mem) / start_mem, 1), '%)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потребление памяти меньше на 49.49 Мб (минус 84.9 %)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59381 entries, 0 to 59380\n",
      "Columns: 133 entries, Id to Product_Info_2_1B\n",
      "dtypes: float16(18), int16(1), int32(1), int8(113)\n",
      "memory usage: 8.8 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = reduce_mem_usage(data)\n",
    "print (data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общий набор столбцов для расчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wt', 'Ht', 'Ins_Age', 'BMI', 'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', 'Insurance_History_4', 'Insurance_History_5', 'Insurance_History_7', 'Insurance_History_8', 'Insurance_History_9', 'Medical_Keyword_1', 'Medical_Keyword_2', 'Medical_Keyword_3', 'Medical_Keyword_4', 'Medical_Keyword_5', 'Medical_Keyword_6', 'Medical_Keyword_7', 'Medical_Keyword_8', 'Medical_Keyword_9', 'Medical_Keyword_10', 'Medical_Keyword_11', 'Medical_Keyword_12', 'Medical_Keyword_13', 'Medical_Keyword_14', 'Medical_Keyword_15', 'Medical_Keyword_16', 'Medical_Keyword_17', 'Medical_Keyword_18', 'Medical_Keyword_19', 'Medical_Keyword_20', 'Medical_Keyword_21', 'Medical_Keyword_22', 'Medical_Keyword_23', 'Medical_Keyword_24', 'Medical_Keyword_25', 'Medical_Keyword_26', 'Medical_Keyword_27', 'Medical_Keyword_28', 'Medical_Keyword_29', 'Medical_Keyword_30', 'Medical_Keyword_31', 'Medical_Keyword_32', 'Medical_Keyword_33', 'Medical_Keyword_34', 'Medical_Keyword_35', 'Medical_Keyword_36', 'Medical_Keyword_37', 'Medical_Keyword_38', 'Medical_Keyword_39', 'Medical_Keyword_40', 'Medical_Keyword_41', 'Medical_Keyword_42', 'Medical_Keyword_43', 'Medical_Keyword_44', 'Medical_Keyword_45', 'Medical_Keyword_46', 'Medical_Keyword_47', 'Medical_Keyword_48', 'Family_Hist_1', 'Family_Hist_2', 'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5', 'Medical_History_1', 'Medical_History_2', 'Medical_History_3', 'Medical_History_4', 'Medical_History_5', 'Medical_History_6', 'Medical_History_7', 'Medical_History_8', 'Medical_History_9', 'Medical_History_10', 'Medical_History_11', 'Medical_History_12', 'Medical_History_13', 'Medical_History_14', 'Medical_History_15', 'Medical_History_16', 'Medical_History_17', 'Medical_History_18', 'Medical_History_19', 'Medical_History_20', 'Medical_History_21', 'Medical_History_22', 'Medical_History_23', 'Medical_History_24', 'Medical_History_25', 'Medical_History_26', 'Medical_History_27', 'Medical_History_28', 'Medical_History_29', 'Medical_History_30', 'Medical_History_31', 'Medical_History_32', 'Medical_History_33', 'Medical_History_34', 'Medical_History_35', 'Medical_History_36', 'Medical_History_37', 'Medical_History_38', 'Medical_History_39', 'Medical_History_40', 'Medical_History_41', 'Product_Info_1', 'Product_Info_3', 'Product_Info_4', 'Product_Info_5', 'Product_Info_6', 'Product_Info_7', 'Product_Info_2_2', 'Product_Info_2_1D', 'Product_Info_2_1A', 'Product_Info_2_1E', 'Product_Info_2_1C', 'Product_Info_2_1B']\n"
     ]
    }
   ],
   "source": [
    "columns_groups = [\"Insurance_History\", \"InsurеdInfo\", \"Medical_Keyword\",\n",
    "                  \"Family_Hist\", \"Medical_History\", \"Product_Info\"]\n",
    "columns = [\"Wt\", \"Ht\", \"Ins_Age\", \"BMI\"]\n",
    "for cg in columns_groups:\n",
    "    columns.extend(data.columns[data.columns.str.startswith(cg)])\n",
    "print (columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "data_transformed = pd.DataFrame(scaler.fit_transform(pd.DataFrame(data,\n",
    "                                                     columns=columns)))\n",
    "columns_transformed = data_transformed.columns\n",
    "data_transformed[\"Response\"] = data[\"Response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение данных\n",
    "Преобразуем выборки в отдельные наборы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6  \\\n",
      "17986 -0.514003 -1.200817  0.365036  0.154055  0.611857 -0.169414  0.862391   \n",
      "23658 -1.265313 -1.687657  0.289513 -0.651001 -1.634368 -0.169414  0.862391   \n",
      "4911  -0.678523 -1.444237  0.592844  0.084137 -1.634368 -0.169414  0.862391   \n",
      "47730 -0.514003 -0.957397 -0.921336 -0.015746  0.611857 -0.169414 -1.159587   \n",
      "11079  0.190693  0.022862  0.365036  0.257933  0.611857 -0.169414  0.862391   \n",
      "\n",
      "              7         8         9  ...       109       110       111  \\\n",
      "17986 -1.013721  0.861368 -0.928723  ... -0.083689  0.441621 -0.149284   \n",
      "23658 -1.013721  0.862242 -0.928723  ... -0.083689  0.441621 -0.149284   \n",
      "4911  -1.013721  0.874351 -0.928723  ... -0.083689 -2.264385 -0.149284   \n",
      "47730  1.101046 -1.156735  1.130555  ... -0.083689  0.441621 -0.149284   \n",
      "11079  0.043662  0.871657 -0.928723  ... -0.083689  0.441621 -0.149284   \n",
      "\n",
      "            112       113       114       115       116       117  Response  \n",
      "17986 -0.666860  0.750845 -0.623305 -0.216001 -0.128866 -0.142142         8  \n",
      "23658  2.134117 -1.331832  1.604350 -0.216001 -0.128866 -0.142142         7  \n",
      "4911  -0.666860  0.750845 -0.623305 -0.216001 -0.128866 -0.142142         6  \n",
      "47730 -0.200031  0.750845 -0.623305 -0.216001 -0.128866 -0.142142         7  \n",
      "11079 -0.666860  0.750845 -0.623305 -0.216001 -0.128866 -0.142142         6  \n",
      "\n",
      "[5 rows x 119 columns]\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(data_transformed,\n",
    "                                         test_size=0.2)\n",
    "data_train = pd.DataFrame(data_train)\n",
    "data_test = pd.DataFrame(data_test)\n",
    "print (data_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия\n",
    "В обучающих данных пометим все классы, кроме 6 и 8, как 0 - и проведем обучение по такому набору данных.\n",
    "\n",
    "Затем в оставшихся данных (в которых класс не равен 6 или 8) заменим все классы, кроме 7 и 1, на 0 - и снова проведем обучение. И т.д. Получим иерархию классификаторов:\n",
    "8/6/нет -> 7/1/нет -> 2/5/нет -> 4/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def regression_model (columns, df):\n",
    "    x = pd.DataFrame(df, columns=columns)\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    model.fit(x, df[\"Response\"])\n",
    "    return model\n",
    "\n",
    "def logistic_regression(columns, df_train):\n",
    "    model = regression_model(columns, df_train)\n",
    "    logr_grid = GridSearchCV(model, {}, cv=5, n_jobs=2,\n",
    "                    scoring=make_scorer(cohen_kappa_score))\n",
    "    x = pd.DataFrame(df_train, columns=columns)\n",
    "    logr_grid.fit(x, df_train[\"Response\"])\n",
    "    return logr_grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимальный набор столбцов\n",
    "Для каждого уровня иерархии это будет свой набор столбцов в исходных данных.\n",
    "\n",
    "### Перекрестная проверка\n",
    "Разбиваем обучающую выборку еще на k (часто 5) частей, на каждой части данных обучаем модель. Затем проверяем 1-ю, 2-ю, 3-ю, 4-ю части на 5; 1-ю, 2-ю, 3-ю, 5-ю части на 4 и т.д.\n",
    "\n",
    "В итоге обучение пройдет весь набор данных, и каждая часть набора будет проверена на всех оставшихся (перекрестным образом)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_opt_columns (data_train):\n",
    "    kappa_score_opt = 0\n",
    "    columns_opt = []\n",
    "    for col in columns_transformed:\n",
    "        kappa_score = logistic_regression([col], data_train)\n",
    "        if kappa_score > kappa_score_opt:\n",
    "            columns_opt = [col]\n",
    "            kappa_score_opt = kappa_score\n",
    "    for col in columns_transformed:\n",
    "        if col not in columns_opt:\n",
    "            columns_opt.append(col)\n",
    "            kappa_score = logistic_regression(columns_opt, data_train)\n",
    "            if kappa_score < kappa_score_opt:\n",
    "                columns_opt.pop()\n",
    "            else:\n",
    "                kappa_score_opt = kappa_score\n",
    "    return columns_opt, kappa_score_opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем последовательно \"урезать\" набор данных при расчете более глубоких моделей: после получения разделения на 8 и остальные отсечем все данные со значением 8, и т.д.\n",
    "\n",
    "После каждого расчета модели будем вычислять значения в проверочной выборке. Проверочную выборку нулями заполнять не будем, иначе оценка будет считаться некорректно.\n",
    "\n",
    "Набор разделений 6/8, 2/5, 1/7, 3/4 дает наибольшую точность"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.4213698840981315 [117, 0, 1, 2, 5, 6, 7, 8, 9, 12, 13, 14, 15, 18, 19, 23, 26, 27, 28, 30, 31, 34, 38, 43, 46, 47, 49, 51, 52, 53, 56, 57, 59, 60, 61, 63, 68, 69, 76, 78, 79, 81, 82, 84, 86, 87, 88, 90, 92, 94, 95, 99, 100, 102, 103, 104, 106, 107, 108, 110, 111, 113, 116]\n",
      "1 0.18589479001417825 [69, 0, 1, 2, 3, 4, 5, 11, 12, 13, 14, 15, 16, 25, 26, 29, 31, 32, 34, 37, 38, 41, 42, 43, 45, 46, 47, 51, 59, 60, 61, 65, 67, 68, 70, 72, 73, 76, 79, 80, 81, 83, 84, 87, 88, 89, 90, 91, 92, 95, 97, 98, 100, 104, 107, 108, 112, 115, 116, 117]\n",
      "2 0.539947145549091 [108, 0, 2, 3, 4, 5, 6, 8, 9, 12, 13, 14, 17, 20, 21, 23, 26, 27, 31, 32, 33, 34, 35, 36, 38, 39, 40, 44, 48, 49, 50, 51, 53, 54, 56, 61, 62, 65, 67, 68, 69, 70, 71, 73, 75, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 99, 101, 102, 104, 106, 107, 111, 112, 114, 115, 117]\n",
      "3 0.45030542885452185 [114, 0, 1, 2, 3, 4, 5, 14, 17, 20, 23, 27, 29, 41, 45, 50, 54, 56, 57, 69, 72, 83, 91, 99, 101, 106]\n"
     ]
    }
   ],
   "source": [
    "responses = [[6, 8], [2, 5], [1, 7], [3, 4]]\n",
    "logr_models = [{}]*len(responses)\n",
    "data_train_current = data_train.copy()\n",
    "i = 0\n",
    "for response in responses:\n",
    "    m_train = data_train_current.copy()\n",
    "    if response != [3,4]:\n",
    "        m_train[\"Response\"] = m_train[\"Response\"].apply(lambda x:0 if x not in response else x)\n",
    "    columns_opt, kappa_score_opt = find_opt_columns(m_train)\n",
    "    print (i, kappa_score_opt, columns_opt)\n",
    "    logr_models[i] = {\n",
    "        \"model\": regression_model(columns_opt, m_train),\n",
    "        \"columns\": columns_opt\n",
    "    }\n",
    "    if response != [3,4]:\n",
    "        data_train_current = data_train_current[~data_train_current[\"Response\"].isin(response)]\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание данных и оценка модели\n",
    "Последовательно считаем предсказания для каждой классификации. После этого объединяем предсказание по иерархии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logr_hierarchy (x):\n",
    "    for response in range(0, len(responses)):\n",
    "        if x[\"target\" + str(response)] > 0:\n",
    "            x[\"target\"] = x[\"target\" + str(response)]\n",
    "            break;\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for response in range(0, len(responses)):\n",
    "    model = logr_models[response][\"model\"]\n",
    "    columns_opt = logr_models[response][\"columns\"]\n",
    "    x = pd.DataFrame(data_test, columns=columns_opt)\n",
    "    data_test[\"target\" + str(response)] = model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6  \\\n",
      "34624  0.895389  1.496539 -0.012580  0.134079  0.611857 -0.169414 -1.159587   \n",
      "49458 -0.160284  0.266282  1.197031 -0.329378  0.611857 -0.169414 -1.159587   \n",
      "8370  -0.583924 -0.463978 -0.391435 -0.427263  0.611857 -0.169414 -1.159587   \n",
      "23368  2.071710  0.516280 -0.921336  2.163699  0.611857 -0.169414  0.862391   \n",
      "56207  1.131202  1.739959  0.062943  0.231964 -1.634368 -0.169414  0.862391   \n",
      "\n",
      "              7         8         9  ...       114       115       116  \\\n",
      "34624  1.101046 -1.156735  1.130555  ... -0.623305 -0.216001 -0.128866   \n",
      "49458  1.101046 -1.156735  1.130555  ... -0.623305 -0.216001 -0.128866   \n",
      "8370   1.101046 -1.156735  1.130555  ...  1.604350 -0.216001 -0.128866   \n",
      "23368 -1.013721  0.866277 -0.928723  ... -0.623305 -0.216001 -0.128866   \n",
      "56207 -1.013721  0.867624 -0.928723  ... -0.623305 -0.216001 -0.128866   \n",
      "\n",
      "            117  Response  target0  target1  target2  target3  target  \n",
      "34624 -0.142142       7.0      0.0      0.0      7.0      4.0     7.0  \n",
      "49458 -0.142142       2.0      0.0      2.0      1.0      3.0     2.0  \n",
      "8370  -0.142142       8.0      8.0      0.0      1.0      4.0     8.0  \n",
      "23368 -0.142142       5.0      0.0      5.0      7.0      3.0     5.0  \n",
      "56207 -0.142142       2.0      0.0      0.0      7.0      4.0     7.0  \n",
      "\n",
      "[5 rows x 124 columns]\n"
     ]
    }
   ],
   "source": [
    "data_test = data_test.apply(logr_hierarchy, axis=1,\n",
    "                            result_type=\"expand\")\n",
    "print (data_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластеризация дает 0.192, kNN(100) - 0.3, простая лог. регрессия - 0.512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Логистическая регрессия, 4 уровня: 0.496\n"
     ]
    }
   ],
   "source": [
    "print (\"Логистическая регрессия, 4 уровня:\",\n",
    "      round(cohen_kappa_score(data_test[\"target\"],\n",
    "                data_test[\"Response\"], weights=\"quadratic\"), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матрица неточностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 457  331   38   23  197  421  132  128]\n",
      " [ 135  236    7    0   72   58   12    8]\n",
      " [  31   44   69   36   86  165   13   10]\n",
      " [  81   54   52  164   23  308   35   68]\n",
      " [  76  156   13    2  208   80   26   16]\n",
      " [  19   18    5   15   19  109   16   36]\n",
      " [ 252  271   16   11  350  788  858  511]\n",
      " [ 204  167    8   29  131  358  487 3128]]\n"
     ]
    }
   ],
   "source": [
    "print (confusion_matrix(data_test[\"target\"],\n",
    "                data_test[\"Response\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
