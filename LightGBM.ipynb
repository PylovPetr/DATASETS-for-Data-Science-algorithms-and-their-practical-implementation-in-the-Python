{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Постановка задачи\n",
    "Загрузим данные, приведем их к числовым, заполним пропуски, нормализуем данные и оптимизируем память.\n",
    "\n",
    "Разделим выборку на обучающую/проверочную в соотношении 80/20.\n",
    "\n",
    "Построим последовательный ансамбль решающих деревьев, используя облегченный градиентный бустинг (LightGBM). Используем перекрестную проверку, чтобы найти наилучшие параметры ансамбля.\n",
    "\n",
    "Проведем предсказание и проверим качество через каппа-метрику.\n",
    "\n",
    "Данные:\n",
    "* https://video.ittensive.com/machine-learning/prudential/train.csv.gz\n",
    "\n",
    "Соревнование: https://www.kaggle.com/c/prudential-life-insurance-assessment/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Подключение библиотек"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, confusion_matrix, make_scorer\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59381 entries, 0 to 59380\n",
      "Columns: 128 entries, Id to Response\n",
      "dtypes: float64(18), int64(109), object(1)\n",
      "memory usage: 58.0+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://video.ittensive.com/machine-learning/prudential/train.csv.gz\")\n",
    "print (data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка данных\n",
    "Дополнительно преобразуем значение класса: начнем его с нуля."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Product_Info_2_1\"] = data[\"Product_Info_2\"].str.slice(0, 1)\n",
    "data[\"Product_Info_2_2\"] = pd.to_numeric(data[\"Product_Info_2\"].str.slice(1, 2))\n",
    "data.drop(labels=[\"Product_Info_2\"], axis=1, inplace=True)\n",
    "for l in data[\"Product_Info_2_1\"].unique():\n",
    "    data[\"Product_Info_2_1\" + l] = data[\"Product_Info_2_1\"].isin([l]).astype(\"int8\")\n",
    "data.drop(labels=[\"Product_Info_2_1\"], axis=1, inplace=True)\n",
    "data.fillna(value=-1, inplace=True)\n",
    "data[\"Response\"] = data[\"Response\"] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Набор столбцов для расчета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Wt', 'Ht', 'Ins_Age', 'BMI', 'Insurance_History_1', 'Insurance_History_2', 'Insurance_History_3', 'Insurance_History_4', 'Insurance_History_5', 'Insurance_History_7', 'Insurance_History_8', 'Insurance_History_9', 'Medical_Keyword_1', 'Medical_Keyword_2', 'Medical_Keyword_3', 'Medical_Keyword_4', 'Medical_Keyword_5', 'Medical_Keyword_6', 'Medical_Keyword_7', 'Medical_Keyword_8', 'Medical_Keyword_9', 'Medical_Keyword_10', 'Medical_Keyword_11', 'Medical_Keyword_12', 'Medical_Keyword_13', 'Medical_Keyword_14', 'Medical_Keyword_15', 'Medical_Keyword_16', 'Medical_Keyword_17', 'Medical_Keyword_18', 'Medical_Keyword_19', 'Medical_Keyword_20', 'Medical_Keyword_21', 'Medical_Keyword_22', 'Medical_Keyword_23', 'Medical_Keyword_24', 'Medical_Keyword_25', 'Medical_Keyword_26', 'Medical_Keyword_27', 'Medical_Keyword_28', 'Medical_Keyword_29', 'Medical_Keyword_30', 'Medical_Keyword_31', 'Medical_Keyword_32', 'Medical_Keyword_33', 'Medical_Keyword_34', 'Medical_Keyword_35', 'Medical_Keyword_36', 'Medical_Keyword_37', 'Medical_Keyword_38', 'Medical_Keyword_39', 'Medical_Keyword_40', 'Medical_Keyword_41', 'Medical_Keyword_42', 'Medical_Keyword_43', 'Medical_Keyword_44', 'Medical_Keyword_45', 'Medical_Keyword_46', 'Medical_Keyword_47', 'Medical_Keyword_48', 'Family_Hist_1', 'Family_Hist_2', 'Family_Hist_3', 'Family_Hist_4', 'Family_Hist_5', 'Medical_History_1', 'Medical_History_2', 'Medical_History_3', 'Medical_History_4', 'Medical_History_5', 'Medical_History_6', 'Medical_History_7', 'Medical_History_8', 'Medical_History_9', 'Medical_History_10', 'Medical_History_11', 'Medical_History_12', 'Medical_History_13', 'Medical_History_14', 'Medical_History_15', 'Medical_History_16', 'Medical_History_17', 'Medical_History_18', 'Medical_History_19', 'Medical_History_20', 'Medical_History_21', 'Medical_History_22', 'Medical_History_23', 'Medical_History_24', 'Medical_History_25', 'Medical_History_26', 'Medical_History_27', 'Medical_History_28', 'Medical_History_29', 'Medical_History_30', 'Medical_History_31', 'Medical_History_32', 'Medical_History_33', 'Medical_History_34', 'Medical_History_35', 'Medical_History_36', 'Medical_History_37', 'Medical_History_38', 'Medical_History_39', 'Medical_History_40', 'Medical_History_41', 'Product_Info_1', 'Product_Info_3', 'Product_Info_4', 'Product_Info_5', 'Product_Info_6', 'Product_Info_7', 'Product_Info_2_2', 'Product_Info_2_1D', 'Product_Info_2_1A', 'Product_Info_2_1E', 'Product_Info_2_1C', 'Product_Info_2_1B']\n"
     ]
    }
   ],
   "source": [
    "columns_groups = [\"Insurance_History\", \"InsurеdInfo\", \"Medical_Keyword\",\n",
    "                  \"Family_Hist\", \"Medical_History\", \"Product_Info\"]\n",
    "columns = [\"Wt\", \"Ht\", \"Ins_Age\", \"BMI\"]\n",
    "for cg in columns_groups:\n",
    "    columns.extend(data.columns[data.columns.str.startswith(cg)])\n",
    "print (columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler()\n",
    "data_transformed = pd.DataFrame(scaler.fit_transform(pd.DataFrame(data,\n",
    "                                                     columns=columns)))\n",
    "columns_transformed = data_transformed.columns\n",
    "data_transformed[\"Response\"] = data[\"Response\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизация памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage (df):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if str(col_type)[:5] == \"float\":\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.finfo(\"f2\").min and c_max < np.finfo(\"f2\").max:\n",
    "                df[col] = df[col].astype(np.float16)\n",
    "            elif c_min > np.finfo(\"f4\").min and c_max < np.finfo(\"f4\").max:\n",
    "                df[col] = df[col].astype(np.float32)\n",
    "            else:\n",
    "                df[col] = df[col].astype(np.float64)\n",
    "        elif str(col_type)[:3] == \"int\":\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if c_min > np.iinfo(\"i1\").min and c_max < np.iinfo(\"i1\").max:\n",
    "                df[col] = df[col].astype(np.int8)\n",
    "            elif c_min > np.iinfo(\"i2\").min and c_max < np.iinfo(\"i2\").max:\n",
    "                df[col] = df[col].astype(np.int16)\n",
    "            elif c_min > np.iinfo(\"i4\").min and c_max < np.iinfo(\"i4\").max:\n",
    "                df[col] = df[col].astype(np.int32)\n",
    "            elif c_min > np.iinfo(\"i8\").min and c_max < np.iinfo(\"i8\").max:\n",
    "                df[col] = df[col].astype(np.int64)\n",
    "        else:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Потребление памяти меньше на', round(start_mem - end_mem, 2), 'Мб (минус', round(100 * (start_mem - end_mem) / start_mem, 1), '%)')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Потребление памяти меньше на 40.49 Мб (минус 75.1 %)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59381 entries, 0 to 59380\n",
      "Columns: 119 entries, 0 to Response\n",
      "dtypes: float16(118), int8(1)\n",
      "memory usage: 13.4 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data_transformed = reduce_mem_usage(data_transformed)\n",
    "print (data_transformed.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разделение данных\n",
    "Преобразуем выборки в отдельные наборы данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0         1         2         3         4         5         6  \\\n",
      "36694 -0.395996 -1.200195  1.273438  0.324707 -1.634766 -0.169434  0.862305   \n",
      "49283 -0.043610  0.269287  1.198242 -0.187134  0.611816 -0.169434  0.862305   \n",
      "47506 -0.395996 -0.465576  0.667969 -0.177368 -1.634766 -0.169434  0.862305   \n",
      "32456  0.802246  0.024353  1.878906  1.023438 -1.634766 -0.169434  0.862305   \n",
      "20731 -1.100586 -0.955078 -0.315918 -0.846191  0.611816 -0.169434 -1.159180   \n",
      "\n",
      "              7         8         9  ...       109       110       111  \\\n",
      "36694 -1.013672  0.862305 -0.928711  ... -0.083679  0.441650 -0.149292   \n",
      "49283 -1.013672  0.862305 -0.928711  ... -0.083679  0.441650 -0.149292   \n",
      "47506 -1.013672  0.864746 -0.928711  ... -0.083679  0.441650 -0.149292   \n",
      "32456 -1.013672  0.862305 -0.928711  ... -0.083679  0.441650 -0.149292   \n",
      "20731  1.100586 -1.156250  1.130859  ... -0.083679 -2.263672 -0.149292   \n",
      "\n",
      "            112       113       114       115       116      117  Response  \n",
      "36694 -0.666992  0.750977 -0.623535 -0.215942 -0.128906 -0.14209         6  \n",
      "49283  2.134766 -1.332031  1.604492 -0.215942 -0.128906 -0.14209         6  \n",
      "47506 -0.200073  0.750977 -0.623535 -0.215942 -0.128906 -0.14209         6  \n",
      "32456 -1.133789 -1.332031 -0.623535  4.628906 -0.128906 -0.14209         1  \n",
      "20731 -0.200073  0.750977 -0.623535 -0.215942 -0.128906 -0.14209         7  \n",
      "\n",
      "[5 rows x 119 columns]\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test = train_test_split(data_transformed,\n",
    "                                         test_size=0.2)\n",
    "data_train = pd.DataFrame(data_train)\n",
    "data_test = pd.DataFrame(data_test)\n",
    "print (data_train.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM\n",
    "Основное отличие этого градиентного бустинга от предыдущих - использование сильно-разнородных (определяется разностью, гистограммой самих данных) экземпляров в выборке для формирования первоначального дерева: сначала рассматриваются все крайние, \"плохие\", случаи, а затем к ним \"достраиваются\" средние, \"хорошие\". Это позволяет еще быстрее минимизировать ошибку моделей.\n",
    "\n",
    "Из дополнительных плюсов: алгоритм запускается сразу на всех ядрах процессора, это существенно ускоряет работу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(data_train, columns=columns_transformed)\n",
    "model = lgb.LGBMRegressor(random_state=17, max_depth=18,\n",
    "                min_child_samples=19, num_leaves=34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также возможно провести классификации множества классов через LightGBM. В этом случае модель вернет вероятности принадлежности к каждому классу, возвращенные значения нужно будет дополнительно обработать через argmax, чтобы получить единственное значение класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''model = lgb.LGBMRegressor(random_state=17, max_depth=17,\n",
    "                min_child_samples=18, num_leaves=34,\n",
    "                objective=\"multiclass\", num_class=8)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Диапазон тестирования параметров модели ограничен только вычислительной мощностью. Для проверки модели имеет смысл провести индивидуальные перекрестные проверки для каждого параметра в отдельности, затем в итоговой проверке перепроверить самые лучшие найденные параметры с отклонением +/-10%.\n",
    "\n",
    "Проверку качества по каппа метрике при оптимизации выполнить не удастся из-за нецелых значений Light GBM. Гиперпараметры оптимизации:\n",
    "* max_depth - максимальная глубина деревьев,\n",
    "* num_leaves - число листьев в каждом\n",
    "* min_child_samples - минимальное число элементов выборке в листе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  42 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=4)]: Done 135 out of 135 | elapsed: 13.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None,\n",
       "                                     colsample_bytree=1.0,\n",
       "                                     importance_type='split', learning_rate=0.1,\n",
       "                                     max_depth=18, min_child_samples=19,\n",
       "                                     min_child_weight=0.001, min_split_gain=0.0,\n",
       "                                     n_estimators=100, n_jobs=-1, num_leaves=34,\n",
       "                                     objective=None, random_state=17,\n",
       "                                     reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "                                     subsample=1.0, subsample_for_bin=200000,\n",
       "                                     subsample_freq=0),\n",
       "             iid='deprecated', n_jobs=4,\n",
       "             param_grid={'max_depth': range(16, 19),\n",
       "                         'min_child_samples': range(17, 20),\n",
       "                         'num_leaves': range(34, 37)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_params = {\n",
    "    'max_depth': range(16,19),\n",
    "    'num_leaves': range(34,37),\n",
    "    'min_child_samples': range(17,20)\n",
    "}\n",
    "grid = GridSearchCV(model, lgb_params, cv=5, n_jobs=4, verbose=True)\n",
    "grid.fit(x, data_train[\"Response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем самые оптимальные параметры и построим итоговую модель, используя 1000 последовательных деревьев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 18, 'min_child_samples': 17, 'num_leaves': 35}\n"
     ]
    }
   ],
   "source": [
    "print (grid.best_params_)\n",
    "model = lgb.LGBMRegressor(random_state=17,\n",
    "    max_depth=grid.best_params_['max_depth'],\n",
    "    min_child_samples=grid.best_params_['min_child_samples'],\n",
    "    num_leaves=grid.best_params_['num_leaves'],\n",
    "    n_estimators=1000,\n",
    "    objective=\"multiclass\", num_class=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "              importance_type='split', learning_rate=0.1, max_depth=18,\n",
       "              min_child_samples=17, min_child_weight=0.001, min_split_gain=0.0,\n",
       "              n_estimators=1000, n_jobs=-1, num_class=8, num_leaves=35,\n",
       "              objective='multiclass', random_state=17, reg_alpha=0.0,\n",
       "              reg_lambda=0.0, silent=True, subsample=1.0,\n",
       "              subsample_for_bin=200000, subsample_freq=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, data_train[\"Response\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предсказание данных и оценка модели\n",
    "LightGBM возвращает дробное значение класса, его нужно округлить.\n",
    "\n",
    "Для multiclass используем argmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_model (x):\n",
    "    return np.argmax(model.predict([x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = pd.DataFrame(data_test, columns=columns_transformed)\n",
    "data_test[\"target\"] = x_test.apply(calculate_model, axis=1,\n",
    "                                  result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кластеризация дает 0.192, kNN(100) - 0.3, лог. регрессия - 0.512/0.496, SVM - 0.95, реш. дерево - 0.3, случайный лес - 0.487, XGBoost - 0.536, градиентный бустинг - 0.56"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM: 0.569\n"
     ]
    }
   ],
   "source": [
    "print (\"LightGBM:\",\n",
    "      round(cohen_kappa_score(data_test[\"target\"],\n",
    "                data_test[\"Response\"], weights=\"quadratic\"), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Матрица неточностей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM\n",
      " [[ 326  158   25   14   41  107   49   34]\n",
      " [ 184  363   22    8  110  107   35   20]\n",
      " [  23   20   76   12    0    0    0    0]\n",
      " [  36   36   71  162    0    4    1    0]\n",
      " [  96  122    7    0  541   75    8    5]\n",
      " [ 231  249   14   23  222 1193  255  123]\n",
      " [ 103  141    3    6   70  314  671  176]\n",
      " [ 222  227    7   38   93  472  555 3571]]\n"
     ]
    }
   ],
   "source": [
    "print (\"LightGBM\\n\",\n",
    "      confusion_matrix(data_test[\"target\"], data_test[\"Response\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
